{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "test_hw5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1_VlqQ_2JrsAZHQyQlm2Z6DhwoPhmaaq1",
      "authorship_tag": "ABX9TyPaXDxRF5fcTdUYTtLnv1Ni",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/johnsocf/CSCI_3202_HW_5/blob/master/test_hw5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMXZFc_qByck"
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IthX7ZtSGFBO",
        "outputId": "5265b017-be8b-427b-b1cb-2e61710b0008",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install scikit-plot"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scikit-plot\n",
            "  Downloading https://files.pythonhosted.org/packages/7c/47/32520e259340c140a4ad27c1b97050dd3254fdc517b1d59974d47037510e/scikit_plot-0.3.7-py3-none-any.whl\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.6/dist-packages (from scikit-plot) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.10 in /usr/local/lib/python3.6/dist-packages (from scikit-plot) (0.17.0)\n",
            "Requirement already satisfied: scipy>=0.9 in /usr/local/lib/python3.6/dist-packages (from scikit-plot) (1.4.1)\n",
            "Requirement already satisfied: matplotlib>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-plot) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.18->scikit-plot) (1.18.5)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.0->scikit-plot) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.0->scikit-plot) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.0->scikit-plot) (0.10.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib>=1.4.0->scikit-plot) (1.15.0)\n",
            "Installing collected packages: scikit-plot\n",
            "Successfully installed scikit-plot-0.3.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xpBaNNgpY7M"
      },
      "source": [
        "import os, sys\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import cv2 as cv\n",
        "import matplotlib.patches as patches\n",
        "import statistics\n",
        "import json\n",
        "import glob\n",
        "import scikitplot as skplt\n",
        "\n",
        "#sci kit learn packages\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import roc_curve,roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# keras packages\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.callbacks import TensorBoard\n",
        "from keras.models import Sequential\n",
        "from keras import backend as K\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.core import Flatten\n",
        "from keras.layers.core import Dropout\n",
        "from keras.layers.core import Dense\n",
        "from keras.layers.experimental.preprocessing import CenterCrop\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from keras.initializers import he_normal\n",
        "from keras.layers import (BatchNormalization, Conv2D, Dense, Dropout, Flatten,\n",
        "                          MaxPool2D, ReLU)\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "\n",
        "# additional packages\n",
        "from google.colab import files\n",
        "from time import time\n",
        "from PIL import Image\n",
        "from operator import itemgetter\n",
        "from matplotlib.pyplot import imread\n",
        "from glob import glob\n",
        "\n",
        "\n"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPGMlqNgzZn7"
      },
      "source": [
        "# Import Competition Data from Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqowS4mWEIEz",
        "outputId": "6e8e5198-deb0-4be8-8b03-81198be96157",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DM5fROBJu_C"
      },
      "source": [
        "%%capture\n",
        "!pip install kaggle\n",
        "!pip install --upgrade kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsvpDJRwPBMn"
      },
      "source": [
        "%%capture\n",
        "!pip install --upgrade --force-reinstall --no-deps kaggle"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFb9uvOtJyp8"
      },
      "source": [
        "!mkdir .kaggle"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5E51iDZTkhp",
        "outputId": "a9c735e6-5024-415b-fb9b-debb8a94b88b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!mkdir .kaggle\n",
        "!ls -a"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘.kaggle’: File exists\n",
            ".  ..  .config\t.kaggle  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhbEy5CMJ79-"
      },
      "source": [
        "token = {\"username\":\"catnippsunn\",\"key\":\"d10a25e54993332212ca4e9f6a8dece2\"}\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsExGfozgR8Q",
        "outputId": "c6d117c5-dca4-45c8-a4fa-791ca982a0d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!mkdir .kaggle\n",
        "!ls -a"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘.kaggle’: File exists\n",
            ".  ..  .config\t.kaggle  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvD8ja0xRtBG"
      },
      "source": [
        "with open('/content/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(token, file)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLe252lQKGqC"
      },
      "source": [
        "!cp /content/.kaggle/kaggle.json ~/.kaggle/kaggle.json"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CRWdljEKKhS",
        "outputId": "590edb5e-54e9-4114-f45a-648ffa175867",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!kaggle config set -n path -v{/content}"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "- path is now set to: {/content}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfLn_bziKQR0"
      },
      "source": [
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G029oeNPOJ4m",
        "outputId": "7b385274-70fa-4c89-89f9-a3c88004daf7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import glob\n",
        "files = glob.glob('/content/*')\n",
        "for f in files:\n",
        "    print('f: ', f)\n",
        "    if os.path.isfile(f):\n",
        "        os.remove(f)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "f:  /content/drive\n",
            "f:  /content/sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z66lEY72Gfwh",
        "outputId": "39b63dc3-02a2-4ef0-d16a-16e0cea21186",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!kaggle competitions download -c histopathologic-cancer-detection -p /content"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading histopathologic-cancer-detection.zip to /content\n",
            "100% 6.30G/6.31G [02:18<00:00, 46.8MB/s]\n",
            "100% 6.31G/6.31G [02:19<00:00, 48.7MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlIJ8AKVLH7k"
      },
      "source": [
        "%%capture\n",
        "!unzip \\*.zip"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTGliOFwbhyD"
      },
      "source": [
        "# set useful paths to image and label directories for succinct use in the notebook\n",
        "model_path = '.'\n",
        "path = '/content/'\n",
        "train_folder = '{}train'.format(path)\n",
        "test_folder = '{}train'.format(path)\n",
        "train_folder_cr = '{}train_cropped'.format(path)\n",
        "test_folder_cr = '{}train_cropped'.format(path)\n",
        "train_label = '{}train_labels.csv'.format(path)\n",
        "sample_submission = '{}sample_submission.csv'.format(path)\n",
        "input_test = '{}test'.format(path)"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtaJoIWxz2y8"
      },
      "source": [
        "Set up variables based on defaults for data directory paths and shapes.  This allows for easy configuration in the model building fitting. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZxlWUKLUGFG",
        "outputId": "02d64e45-fae3-400f-cae9-ec6c5226209c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "directory_for_training = train_folder\n",
        "data_shape = (96, 96, 3)\n",
        "dims = (data_shape[0], data_shape[1])\n",
        "dims"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(96, 96)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQgVbvZ5J5VH",
        "outputId": "14ab7928-dd7d-4480-e3f3-7f3828413630",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "label_data_df = pd.read_csv(train_label)\n",
        "label_data_df[\"file_name\"] = label_data_df[\"id\"].apply(lambda x: x + \".tif\")\n",
        "\n",
        "sample_size = 80000\n",
        "id_label_pos = label_data_df.loc[label_data_df[\"label\"] == 1, :].sample(n=sample_size)\n",
        "id_label_neg = label_data_df.loc[label_data_df[\"label\"] == 0, :].sample(n=sample_size)\n",
        "id_label = pd.concat([id_label_pos, id_label_neg], ignore_index=True)\n",
        "del id_label_pos, id_label_neg\n",
        "\n",
        "id_label_train, id_label_val = train_test_split(id_label, test_size=0.1, stratify=id_label[\"label\"])\n",
        "id_label_train.reset_index(drop=True, inplace=True)\n",
        "id_label_val.reset_index(drop=True, inplace=True)\n",
        "len_train = id_label_train.shape[0]\n",
        "len_val = id_label_val.shape[0]\n",
        "print(\"Training data size: {}.\".format(len_train))\n",
        "print(\"Validation data size: {}.\".format(len_val))\n",
        "del id_label"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data size: 144000.\n",
            "Validation data size: 16000.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWWgq53mQRXi"
      },
      "source": [
        "## Labels Dataframe Preprocessing\n",
        "\n",
        "The Binary Class Mode in Keras preprocessing requires classes to be Strings.  This necessitates a translation from the stored data set which has classes stored as 0 and 1 format to represent negative and positive images, respectively.\n",
        "Ref: https://keras.io/api/preprocessing/image/\n",
        "\n",
        "The image ID in the label data set needs to also be adjusted to include the file extension since the mapping of ID will be used directly look up the image in the training and verification directories subsequent steps to set up the CNN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwifzpfE5l0O"
      },
      "source": [
        "# update labels since `class_mode='binary' requires classes to be strings.\n",
        "id_label_train['label'] = np.where(id_label_train['label'] == 0, 'neg','pos')\n",
        "id_label_val['label'] = np.where(id_label_val['label'] == 0, 'neg','pos')\n",
        "# update image IDs to include the .tif file format for proper processing in\n",
        "# subsequent steps.\n",
        "id_label_train['id'] = id_label_train['id'] + '.tif'\n",
        "id_label_val['id'] = id_label_val['id'] + '.tif'"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_oep-OPPZIRX",
        "outputId": "cab6ab18-dd89-4b51-aa40-dd66f1e518d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "id_label_val"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>file_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ff4762d2b984b754f5542f5649f988e9dbbe7164.tif</td>\n",
              "      <td>pos</td>\n",
              "      <td>ff4762d2b984b754f5542f5649f988e9dbbe7164.tif</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>e5c02c781afb181e9e890ce886fdb10348934a75.tif</td>\n",
              "      <td>pos</td>\n",
              "      <td>e5c02c781afb181e9e890ce886fdb10348934a75.tif</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0b9321022cf7f92fdd6b45ef00b537fed9eace2d.tif</td>\n",
              "      <td>neg</td>\n",
              "      <td>0b9321022cf7f92fdd6b45ef00b537fed9eace2d.tif</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5e8b638380a25b5d48658f32b25bad069ad35ad3.tif</td>\n",
              "      <td>pos</td>\n",
              "      <td>5e8b638380a25b5d48658f32b25bad069ad35ad3.tif</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2ab9afcd4e94d485cdba536a5d7d29b60aecdcc5.tif</td>\n",
              "      <td>neg</td>\n",
              "      <td>2ab9afcd4e94d485cdba536a5d7d29b60aecdcc5.tif</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15995</th>\n",
              "      <td>6b3c57b3b05da35ce58a0508b48b262199c9875f.tif</td>\n",
              "      <td>neg</td>\n",
              "      <td>6b3c57b3b05da35ce58a0508b48b262199c9875f.tif</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15996</th>\n",
              "      <td>12ff29afe3c056e32df58d29181893c74ea1f699.tif</td>\n",
              "      <td>pos</td>\n",
              "      <td>12ff29afe3c056e32df58d29181893c74ea1f699.tif</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15997</th>\n",
              "      <td>a5c0568834f78b98ef521844915f365ba517ce08.tif</td>\n",
              "      <td>neg</td>\n",
              "      <td>a5c0568834f78b98ef521844915f365ba517ce08.tif</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15998</th>\n",
              "      <td>da3868352a777baf8eeaad87883e6ccf6b593320.tif</td>\n",
              "      <td>neg</td>\n",
              "      <td>da3868352a777baf8eeaad87883e6ccf6b593320.tif</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15999</th>\n",
              "      <td>055534835204a62763f7b2dde1d86bbf77120f99.tif</td>\n",
              "      <td>pos</td>\n",
              "      <td>055534835204a62763f7b2dde1d86bbf77120f99.tif</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>16000 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 id  ...                                     file_name\n",
              "0      ff4762d2b984b754f5542f5649f988e9dbbe7164.tif  ...  ff4762d2b984b754f5542f5649f988e9dbbe7164.tif\n",
              "1      e5c02c781afb181e9e890ce886fdb10348934a75.tif  ...  e5c02c781afb181e9e890ce886fdb10348934a75.tif\n",
              "2      0b9321022cf7f92fdd6b45ef00b537fed9eace2d.tif  ...  0b9321022cf7f92fdd6b45ef00b537fed9eace2d.tif\n",
              "3      5e8b638380a25b5d48658f32b25bad069ad35ad3.tif  ...  5e8b638380a25b5d48658f32b25bad069ad35ad3.tif\n",
              "4      2ab9afcd4e94d485cdba536a5d7d29b60aecdcc5.tif  ...  2ab9afcd4e94d485cdba536a5d7d29b60aecdcc5.tif\n",
              "...                                             ...  ...                                           ...\n",
              "15995  6b3c57b3b05da35ce58a0508b48b262199c9875f.tif  ...  6b3c57b3b05da35ce58a0508b48b262199c9875f.tif\n",
              "15996  12ff29afe3c056e32df58d29181893c74ea1f699.tif  ...  12ff29afe3c056e32df58d29181893c74ea1f699.tif\n",
              "15997  a5c0568834f78b98ef521844915f365ba517ce08.tif  ...  a5c0568834f78b98ef521844915f365ba517ce08.tif\n",
              "15998  da3868352a777baf8eeaad87883e6ccf6b593320.tif  ...  da3868352a777baf8eeaad87883e6ccf6b593320.tif\n",
              "15999  055534835204a62763f7b2dde1d86bbf77120f99.tif  ...  055534835204a62763f7b2dde1d86bbf77120f99.tif\n",
              "\n",
              "[16000 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CS8wY6nKmMh",
        "outputId": "440b98ae-1951-4109-b565-1fd636516111",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "train_folder"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/train'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-gfAw7LeBR5",
        "outputId": "395abacb-cc6b-4b49-f34b-c78976475d43",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "img_gen_params = {\n",
        "    \"rescale\": 1.0 / 255,\n",
        "    \"samplewise_center\": True,\n",
        "    \"samplewise_std_normalization\": True,\n",
        "    \"horizontal_flip\": True,\n",
        "    \"vertical_flip\": True\n",
        "}\n",
        "\n",
        "img_gen = ImageDataGenerator(**img_gen_params)\n",
        "\n",
        "IMAGE_SHAPE = (96, 96, 3)\n",
        "batch_size = 32\n",
        "\n",
        "img_flow_params_train = {\n",
        "    \"dataframe\": id_label_train,\n",
        "    \"directory\": train_folder,\n",
        "    \"x_col\": \"id\",\n",
        "    \"y_col\": \"label\",\n",
        "    \"batch_size\": batch_size,\n",
        "    \"target_size\": IMAGE_SHAPE[:2],\n",
        "}\n",
        "\n",
        "img_flow_train = img_gen.flow_from_dataframe(**img_flow_params_train)\n",
        "\n",
        "img_flow_params_val = {\n",
        "    \"dataframe\": id_label_val,\n",
        "    \"directory\": train_folder,\n",
        "    \"x_col\": \"id\",\n",
        "    \"y_col\": \"label\",\n",
        "    \"batch_size\": 1,\n",
        "    \"shuffle\": False,\n",
        "    \"target_size\": IMAGE_SHAPE[:2],\n",
        "}\n",
        "\n",
        "img_flow_val = img_gen.flow_from_dataframe(**img_flow_params_val)\n",
        "\n",
        "\n",
        "model = keras.models.Sequential()\n",
        "\n",
        "model.add(Conv2D(filters[0], kernel_size, padding=\"same\", kernel_initializer=he_normal(), input_shape=IMAGE_SHAPE))\n",
        "model.add(BatchNormalization())\n",
        "model.add(ReLU())\n",
        "model.add(Conv2D(filters[0], kernel_size, padding=\"same\", kernel_initializer=he_normal()))\n",
        "model.add(BatchNormalization())\n",
        "model.add(ReLU())\n",
        "model.add(MaxPool2D())\n",
        "model.add(Dropout(drop_prob_conv))\n",
        "\n",
        "model.add(Conv2D(filters[1], kernel_size, padding=\"same\", kernel_initializer=he_normal()))\n",
        "model.add(BatchNormalization())\n",
        "model.add(ReLU())\n",
        "model.add(Conv2D(filters[1], kernel_size, padding=\"same\", kernel_initializer=he_normal()))\n",
        "model.add(BatchNormalization())\n",
        "model.add(ReLU())\n",
        "model.add(MaxPool2D())\n",
        "model.add(Dropout(drop_prob_conv))\n",
        "\n",
        "model.add(Conv2D(filters[2], kernel_size, padding=\"same\", kernel_initializer=he_normal()))\n",
        "model.add(BatchNormalization())\n",
        "model.add(ReLU())\n",
        "model.add(Conv2D(filters[2], kernel_size, padding=\"same\", kernel_initializer=he_normal()))\n",
        "model.add(BatchNormalization())\n",
        "model.add(ReLU())\n",
        "model.add(MaxPool2D())\n",
        "model.add(Dropout(drop_prob_conv))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(BatchNormalization())\n",
        "model.add(ReLU())\n",
        "model.add(Dropout(drop_prob_dense))\n",
        "model.add(Dense(256))\n",
        "model.add(BatchNormalization())\n",
        "model.add(ReLU())\n",
        "model.add(Dropout(drop_prob_dense))\n",
        "model.add(Dense(2, activation=\"softmax\"))\n",
        "model.compile(Adam(0.01), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 144000 validated image filenames belonging to 2 classes.\n",
            "Found 16000 validated image filenames belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXeEw1czIKpM",
        "outputId": "a428aff9-ad9b-497c-a958-d0fda2b419e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        }
      },
      "source": [
        "\n",
        "lr_decay_params = {\n",
        "    \"monitor\": \"val_acc\",\n",
        "    \"factor\": 0.5,\n",
        "    \"patience\": 1,\n",
        "    \"min_lr\": 1e-5\n",
        "}\n",
        "lr_decay = ReduceLROnPlateau(**lr_decay_params)\n",
        "\n",
        "early_stopping = EarlyStopping(monitor=\"val_acc\", patience=3, verbose=1)\n",
        "\n",
        "\n",
        "# TODO (find additional reference for this setup.)\n",
        "STEP_SIZE_TRAINING=img_flow_train.n//img_flow_train.batch_size\n",
        "# Total number of images in the data set / batch size \n",
        "# (batch size is set in preprocessing api above).\n",
        "STEP_SIZE_TESTING=img_flow_train.n//img_flow_train.batch_size\n",
        "\n",
        "fit_params = {\n",
        "    \"generator\": img_flow_train,\n",
        "    \"steps_per_epoch\": STEP_SIZE_TRAINING,\n",
        "    \"epochs\": 10,\n",
        "    \"verbose\": 1,\n",
        "    \"validation_data\": img_flow_val,\n",
        "    \"validation_steps\": STEP_SIZE_TESTING,\n",
        "    #\"callbacks\": [lr_decay, early_stopping]\n",
        "}\n",
        "print(\"Training the model...\")\n",
        "model.fit_generator(**fit_params)\n",
        "print(\"Done!\")\n"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training the model...\n",
            "Epoch 1/10\n",
            " 131/4500 [..............................] - ETA: 5:26 - loss: 0.6664 - accuracy: 0.7078"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-115-d5c8cc1ff2eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m }\n\u001b[1;32m     28\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training the model...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Done!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1827\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1828\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1829\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1831\u001b[0m   @deprecation.deprecated(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ER9weuSsT51h"
      },
      "source": [
        "ref on, 'fit or fit_generator':  https://www.geeksforgeeks.org/keras-fit-and-keras-fit_generator/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IyoGbE8td-n0"
      },
      "source": [
        "## Metric Analysis Data Viz on Performance\n",
        "\n",
        "Display the Confusion Matrix and Classification Reports for the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHi6w4rjY_lv",
        "outputId": "51769674-5bcd-4314-a507-e5e765d6bdfd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "test_steps_per_epoch = np.math.ceil(img_flow_val.samples / img_flow_val.batch_size)\n",
        "\n",
        "predictions = model.predict_generator(img_flow_val, steps=test_steps_per_epoch)\n"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-118-48cdb2cc1420>:3: Model.predict_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.predict, which supports generators.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7eBMjXfo-fL"
      },
      "source": [
        "# predicted_classes = np.argmax(predictions, axis=1)\n",
        "# true_classes = img_flow_val.classes\n",
        "# class_labels = list(img_flow_val.class_indices.keys())   \n"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxVMet8T22xX"
      },
      "source": [
        "def plot_roc_curve(fpr,tpr): \n",
        "  plt.plot([0, 1], [0, 1], \"k--\")\n",
        "  plt.plot(fpr, tpr, label=\"ACC={:.4F}, AUC={:.4f}\".format(acc_val, auc_val))\n",
        "  plt.xlabel(\"False positive rate\")\n",
        "  plt.ylabel(\"True positive rate\")\n",
        "  plt.title(\"ROC curve\")\n",
        "  plt.legend(loc=\"best\")\n",
        "  plt.show()\n",
        "  plt.savefig(\"roc_curve.png\")"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZIYK_LBsQt4",
        "outputId": "5f6b7605-8023-49cf-b857-8fcb849d096e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "source": [
        "from sklearn.metrics import auc, roc_curve, confusion_matrix, classification_report\n",
        "len_val = id_label_val.shape[0]\n",
        "y_val_pred = model.predict_generator(img_flow_val, steps=test_steps_per_epoch)[:, 1]\n",
        "y_val_true = img_flow_val.classes\n",
        "acc_val = np.equal((y_val_pred > 0.5).astype(\"int\"), y_val_true).sum() / y_val_pred.shape[0]\n",
        "print(\"Validation accuracy: {:.3f}.\".format(acc_val))\n",
        "print(y_val_pred.shape)\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(y_val_true, y_val_pred)\n",
        "auc_val = auc(fpr, tpr)\n",
        "print(\"Validation AUC: {:.3f}.\".format(auc_val))\n",
        "\n",
        "plot_roc_curve(fpr,tpr)\n",
        "\n"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation accuracy: 0.731.\n",
            "(16000,)\n",
            "Validation AUC: 0.821.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7JO4zMOBQGI",
        "outputId": "99b16ca3-04b1-44a1-e859-e78c3897a514",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(len(y_val_pred))\n",
        "print(len(y_val_true))\n",
        "model_orig.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16000\n",
            "16000\n",
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_157 (Conv2D)          (None, 96, 96, 16)        448       \n",
            "_________________________________________________________________\n",
            "conv2d_158 (Conv2D)          (None, 96, 96, 16)        2320      \n",
            "_________________________________________________________________\n",
            "conv2d_159 (Conv2D)          (None, 96, 96, 16)        2320      \n",
            "_________________________________________________________________\n",
            "dropout_70 (Dropout)         (None, 96, 96, 16)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_54 (MaxPooling (None, 32, 32, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_160 (Conv2D)          (None, 32, 32, 32)        4640      \n",
            "_________________________________________________________________\n",
            "conv2d_161 (Conv2D)          (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "conv2d_162 (Conv2D)          (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "dropout_71 (Dropout)         (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_55 (MaxPooling (None, 10, 10, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_163 (Conv2D)          (None, 10, 10, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_164 (Conv2D)          (None, 10, 10, 64)        36928     \n",
            "_________________________________________________________________\n",
            "conv2d_165 (Conv2D)          (None, 10, 10, 64)        36928     \n",
            "_________________________________________________________________\n",
            "dropout_72 (Dropout)         (None, 10, 10, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_56 (MaxPooling (None, 3, 3, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_166 (Conv2D)          (None, 3, 3, 128)         73856     \n",
            "_________________________________________________________________\n",
            "conv2d_167 (Conv2D)          (None, 3, 3, 128)         147584    \n",
            "_________________________________________________________________\n",
            "conv2d_168 (Conv2D)          (None, 3, 3, 128)         147584    \n",
            "_________________________________________________________________\n",
            "dropout_73 (Dropout)         (None, 3, 3, 128)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_57 (MaxPooling (None, 1, 1, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_14 (Flatten)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_28 (Dense)             (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dropout_74 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_29 (Dense)             (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 506,241\n",
            "Trainable params: 506,241\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPMN1QDOAaxj",
        "outputId": "b67b5311-915b-4fb7-8049-def1c97734e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(confusion_matrix(y_val_true, y_val_pred.round()))\n",
        "report = classification_report(y_val_true, y_val_pred.round(), target_names=class_labels)\n",
        "\n",
        "from sklearn.metrics import classification_report, roc_curve\n",
        "print(report) \n",
        "print(confusion_matrix(y_val_true, y_val_pred.round()))"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[7030  970]\n",
            " [3329 4671]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         neg       0.68      0.88      0.77      8000\n",
            "         pos       0.83      0.58      0.68      8000\n",
            "\n",
            "    accuracy                           0.73     16000\n",
            "   macro avg       0.75      0.73      0.73     16000\n",
            "weighted avg       0.75      0.73      0.73     16000\n",
            "\n",
            "[[7030  970]\n",
            " [3329 4671]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9iCM9-RCMQk"
      },
      "source": [
        "## Submission"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFw3b-iaCL8t"
      },
      "source": [
        "test_df = pd.read_csv(sample_submission)\n",
        "\n",
        "TESTING_BATCH_SIZE = 64\n",
        "# get test files\n",
        "testing_files = glob(os.path.join(input_test,'*.tif'))\n",
        "# create empty pandas dataframe\n",
        "submission = pd.DataFrame()\n",
        "print(len(testing_files))\n",
        "# 10 should be: len(testing_files)\n",
        "for index in range(0, len(testing_files), TESTING_BATCH_SIZE):\n",
        "    data_frame = pd.DataFrame({'path': testing_files[index:index+TESTING_BATCH_SIZE]})\n",
        "    # parse in IDs and Images for each test file item\n",
        "    data_frame['id'] = data_frame.path.map(lambda x: x.split('/')[3].split(\".\")[0])\n",
        "    data_frame['image'] = data_frame['path'].map(imread)\n",
        "    # join image array\n",
        "    images = np.stack(data_frame.image, axis=0)\n",
        "    ids = np.stack(data_frame.id, axis=0)\n",
        "    # expand dims restructures shape for the image in precitions by expanding it.\n",
        "    predicted_labels = [model_orig.predict(np.expand_dims(image/255.0, axis=0))[0][0] for image in images]\n",
        "    # make a prediction array\n",
        "    predictions = np.array(predicted_labels)\n",
        "    # assign predictions to a new label column in the df\n",
        "    data_frame['label'] = predictions\n",
        "    # can remove this for actual submission, this is more for metric data vis.\n",
        "    # add frame to existing submission df\n",
        "    submission = pd.concat([submission, data_frame[[\"id\", \"label\"]]])\n",
        "    # mark the passing of time with a log\n",
        "    if index % 1000 == 0 :\n",
        "        print(index/len(testing_files) * 100)\n",
        "# convert the submission to a csv\n",
        "submission.to_csv('submission_aug_v1.csv', index=False, header=True)\n",
        "print(submission.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eu7t4R6qa10I"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYOivtptTek-"
      },
      "source": [
        "!cp submission_aug_v1.csv \"drive/My Drive/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKMxPEzDftbh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XteJZ1fTYv98"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVDQX62EVHTT"
      },
      "source": [
        "# modularize the submission code.\n",
        "# get prediction labels from df.\n",
        "# get classes.\n",
        "# pass to metric data vis module."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7gzWefB2Khh"
      },
      "source": [
        "refs: \n",
        "https://androidkt.com/get-the-roc-curve-and-auc-for-keras-model/\n",
        "\n",
        "https://tduan.netlify.app/post/ai-from-the-data-center-to-the-edge-training-by-intel/part3-model_analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Dz98hokvABJ"
      },
      "source": [
        "# Are under the ROC curve."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raCiyEcSkTxG"
      },
      "source": [
        "# max: 0.9179 on non cropped images.\n",
        "# .86/ 20 epoch with cropped images and standard.\n",
        "# .599/ 20 cropped and nonstandard."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUyv21ZgkCse"
      },
      "source": [
        "# metrics:  https://towardsdatascience.com/the-5-classification-evaluation-metrics-you-must-know-aa97784ff226\n",
        "# accuracy, precision, recall.\n",
        "# f1, log loss (specific for binary classification), auc\n",
        "\n",
        "# howto?  calc myself or use classificationReport from scikit\n",
        "# https://datascience.stackexchange.com/questions/45165/how-to-get-accuracy-f1-precision-and-recall-for-a-keras-model\n",
        "# https://keras.io/api/metrics/accuracy_metrics/#binaryaccuracy-class"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kYv2bEODxPS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}